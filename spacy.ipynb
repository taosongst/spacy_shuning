{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Treblinka is a small village in Poland.', {'entities': [[0, 9, 'GPE']]}], ['Wikipedia notes that Treblinka is not large.', {'entities': [[21, 30, 'GPE']]}]]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Treblinka is a small village in Poland. Wikipedia notes that Treblinka is not large.\"\n",
    "corpus = []\n",
    "\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    corpus.append(sent.text)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "patterns = [\n",
    "                {\"label\": \"GPE\", \"pattern\": \"Treblinka\"}\n",
    "            ]\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "TRAIN_DATA = []\n",
    "for sentence in corpus:\n",
    "    doc = nlp(sentence)\n",
    "    entities = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        entities.append([ent.start_char, ent.end_char, ent.label_])\n",
    "    TRAIN_DATA.append([sentence, {\"entities\": entities}])\n",
    "\n",
    "print (TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "import typer\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "def convert(lang: str, TRAIN_DATA, output_path: Path):\n",
    "    nlp = spacy.blank(lang)\n",
    "    db = DocBin()\n",
    "    for text, annot in TRAIN_DATA:\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span is None:\n",
    "                msg = f\"Skipping entity [{start}, {end}, {label}] in the following text because the character span '{doc.text[start:end]}' does not align with token boundaries:\\n\\n{repr(text)}\\n\"\n",
    "                warnings.warn(msg)\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%html\n",
    "# <div align=\"center\">\n",
    "# <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TKoPva69_6E\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(\"en\", TRAIN_DATA, \"data/train.spacy\")\n",
    "convert(\"en\", TRAIN_DATA, \"data/valid.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "data\\config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config data/base_config.cfg data/config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-11-22 23:37:55,969] [INFO] Set up nlp object from config\n",
      "[2021-11-22 23:37:55,976] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-11-22 23:37:55,979] [INFO] Created vocabulary\n",
      "[2021-11-22 23:37:55,980] [INFO] Finished initializing nlp object\n",
      "[2021-11-22 23:37:56,028] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] No output directory provided\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00      7.83   25.00   14.29  100.00    0.25\n",
      "200     200          0.20     98.13  100.00  100.00  100.00    1.00\n",
      "400     400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "600     600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "800     800          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1000    1000          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1200    1200          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1400    1400          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1600    1600          0.00      0.00  100.00  100.00  100.00    1.00\n",
      "1800    1800          0.00      0.00  100.00  100.00  100.00    1.00\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train data/config.cfg --paths.train ./data/train.spacy --paths.dev ./data/valid.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
