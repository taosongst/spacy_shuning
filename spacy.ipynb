{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91377763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Treblinka is a small village in Poland.', {'entities': [[0, 9, 'GPE']]}], ['Wikipedia notes that Treblinka is not large.', {'entities': [[21, 30, 'GPE']]}]]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Treblinka is a small village in Poland. Wikipedia notes that Treblinka is not large.\"\n",
    "corpus = []\n",
    "\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    corpus.append(sent.text)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "patterns = [\n",
    "                {\"label\": \"GPE\", \"pattern\": \"Treblinka\"}\n",
    "            ]\n",
    "\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "TRAIN_DATA = []\n",
    "for sentence in corpus:\n",
    "    doc = nlp(sentence)\n",
    "    entities = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        entities.append([ent.start_char, ent.end_char, ent.label_])\n",
    "    TRAIN_DATA.append([sentence, {\"entities\": entities}])\n",
    "\n",
    "print (TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31aedf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "import typer\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "def convert(lang: str, TRAIN_DATA, output_path: Path):\n",
    "    nlp = spacy.blank(lang)\n",
    "    db = DocBin()\n",
    "    for text, annot in TRAIN_DATA:\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annot[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span is None:\n",
    "                msg = f\"Skipping entity [{start}, {end}, {label}] in the following text because the character span '{doc.text[start:end]}' does not align with token boundaries:\\n\\n{repr(text)}\\n\"\n",
    "                warnings.warn(msg)\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39b043a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%html\n",
    "# <div align=\"center\">\n",
    "# <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TKoPva69_6E\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b62dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(\"en\", TRAIN_DATA, \"train.spacy\")\n",
    "convert(\"en\", TRAIN_DATA, \"valid.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7696cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Auto-filled config with all values\n",
      "[+] Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 23:16:43.152248: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-11-22 23:16:43.152273: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30b0014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] No output directory provided\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 23:20:32.946160: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-11-22 23:20:32.946203: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2021-11-22 23:20:35,884] [INFO] Set up nlp object from config\n",
      "[2021-11-22 23:20:35,891] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-11-22 23:20:35,894] [INFO] Created vocabulary\n",
      "[2021-11-22 23:20:35,895] [INFO] Finished initializing nlp object\n",
      "[2021-11-22 23:20:35,967] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "OMP: Error #15: Initializing libiomp5md.dll, but found libiomp5md.dll already initialized.\n",
      "OMP: Hint This means that multiple copies of the OpenMP runtime have been linked into the program. That is dangerous, since it can degrade performance or cause incorrect results. The best thing to do is to ensure that only a single OpenMP runtime is linked into the process, e.g. by avoiding static linking of the OpenMP runtime in any library. As an unsafe, unsupported, undocumented workaround you can set the environment variable KMP_DUPLICATE_LIB_OK=TRUE to allow the program to continue to execute, but that may cause crashes or silently produce incorrect results. For more information, please see http://www.intel.com/software/products/support/.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00ae2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Saving to output directory: models\\output\n",
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 23:16:48.477528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-11-22 23:16:48.477552: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2021-11-22 23:16:51,485] [INFO] Set up nlp object from config\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\spacy\\__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\spacy\\cli\\_util.py\", line 71, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\click\\core.py\", line 1137, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\click\\core.py\", line 1062, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\click\\core.py\", line 1668, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\click\\core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\click\\core.py\", line 763, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\typer\\main.py\", line 500, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\spacy\\cli\\train.py\", line 45, in train_cli\n",
      "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\spacy\\cli\\train.py\", line 72, in train\n",
      "    nlp = init_nlp(config, use_gpu=use_gpu)\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\spacy\\training\\initialize.py\", line 59, in init_nlp\n",
      "    train_corpus, dev_corpus = resolve_dot_names(config, dot_names)\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\spacy\\util.py\", line 575, in resolve_dot_names\n",
      "    result = registry.resolve(config[section])\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\thinc\\config.py\", line 729, in resolve\n",
      "    resolved, _ = cls._make(\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\thinc\\config.py\", line 778, in _make\n",
      "    filled, _, resolved = cls._fill(\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\thinc\\config.py\", line 850, in _fill\n",
      "    getter_result = getter(*args, **kwargs)\n",
      "  File \"C:\\Users\\tao\\Anaconda3\\lib\\site-packages\\spacy\\training\\corpus.py\", line 31, in create_docbin_reader\n",
      "    raise ValueError(Errors.E913)\n",
      "ValueError: [E913] Corpus path can't be None. Maybe you forgot to define it in your config.cfg or override it on the CLI?\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./models/output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849ed53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
